{
  "Home": "主页",
  "Train": "训练",
  "About": "关于",
  "Settings": "设置",
  "Go to chat page": "前往聊天页",
  "Manage your configs": "管理你的配置",
  "Manage models": "管理模型",
  "Run": "运行",
  "Offline": "离线",
  "Starting": "启动中",
  "Loading": "读取模型中",
  "Working": "运行中",
  "Stop": "停止",
  "Enable High Precision For Last Layer": "输出层使用高精度",
  "Stored Layers": "载入显存层数",
  "Precision": "精度",
  "Device": "设备",
  "Convert model with these configs. Using a converted model will greatly improve the loading speed, but model parameters of the converted model cannot be modified.": "用这些设置转换模型. 使用转换过的模型能大大提升载入速度, 但是转换后的模型无法再修改模型参数.",
  "Manage Models": "管理模型",
  "Model": "模型",
  "Model Parameters": "模型参数",
  "Frequency Penalty": "Frequency Penalty",
  "Presence Penalty": "Presence Penalty",
  "Top_P": "Top_P",
  "Temperature": "Temperature",
  "Max Response Token": "最大响应 Token",
  "API Port": "API 端口",
  "Hover your mouse over the text to view a detailed description. Settings marked with * will take effect immediately after being saved.": "把鼠标悬停在文本上查看详细描述. 标记了星号 * 的设置在保存后会立即生效.",
  "Default API Parameters": "默认 API 参数",
  "Provide JSON file URLs for the models manifest. Separate URLs with semicolons. The \"models\" field in JSON files will be parsed into the following table.": "填写模型描述的 JSON 文件地址. 地址间用分号分隔. JSON 文件内的 \"models\" 字段会被分析进下表.",
  "Config Name": "配置名",
  "Refresh": "刷新",
  "Save Config": "保存配置",
  "Model Source Manifest List": "模型源",
  "Models": "模型",
  "Delete Config": "删除配置",
  "Help": "帮助",
  "Version": "版本",
  "New Config": "新建配置",
  "Open Url": "打开网页",
  "Download": "下载",
  "Open Folder": "打开文件夹",
  "Configs": "配置",
  "Automatic Updates Check": "自动检查更新",
  "Updates Check Error": "检查更新失败",
  "Introduction": "介绍",
  "Dark Mode": "深色模式",
  "Language": "语言",
  "In Development": "开发中",
  "Chat": "聊天",
  "Convert": "转换",
  "Actions": "动作",
  "Last updated": "上次更新",
  "Desc": "描述",
  "Size": "文件大小",
  "File": "文件",
  "Config Saved": "配置已保存",
  "Downloading": "正在下载",
  "Loading Model": "正在读取模型",
  "Startup Completed": "启动完成",
  "Failed to switch model": "切换模型失败",
  "Start Converting": "开始转换",
  "Convert Success": "转换成功",
  "Convert Failed": "转换失败",
  "Model Not Found": "模型不存在",
  "Model Status": "模型状态",
  "Clear": "清除",
  "Send": "发送",
  "Type your message here": "在此输入消息",
  "Copy": "复制",
  "Read Aloud": "朗读",
  "Hello! I'm RWKV, an open-source and commercially usable large language model.": "你好！我是RWKV，一个开源可商用的大语言模型。",
  "This tool's API is compatible with OpenAI API. It can be used with any ChatGPT tool you like. Go to the settings of some ChatGPT tool, replace the 'https://api.openai.com' part in the API address with '": "本工具的API与OpenAI API兼容. 因此可以配合任意你喜欢的ChatGPT工具使用. 打开某个ChatGPT工具的设置, 将API地址中的'https://api.openai.com'部分替换为'",
  "New Version Available": "新版本可用",
  "Update": "更新",
  "Please click the button in the top right corner to start the model": "请点击右上角的按钮启动模型",
  "Update Error": "更新出错",
  "Open the following URL with your browser to view the API documentation": "使用浏览器打开以下地址查看API文档",
  "By default, the maximum number of tokens that can be answered in a single response, it can be changed by the user by specifying API parameters.": "默认情况下, 单个回复最多回答的token数目, 用户可以通过自行指定API参数改变这个值",
  "Sampling temperature, it's like giving alcohol to a model, the higher the stronger the randomness and creativity, while the lower, the more focused and deterministic it will be.": "采样温度, 就像给模型喝酒, 越大随机性越强, 更具创造力, 越小则越保守稳定",
  "Just like feeding sedatives to the model. Consider the results of the top n% probability mass, 0.1 considers the top 10%, with higher quality but more conservative, 1 considers all results, with lower quality but more diverse.": "就像给模型喂镇静剂. 考虑前 n% 概率质量的结果, 0.1 考虑前 10%, 质量更高, 但更保守, 1 考虑所有质量结果, 质量降低, 但更多样",
  "Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.": "存在惩罚. 正值根据新token在至今的文本中是否出现过, 来对其进行惩罚, 从而增加了模型涉及新话题的可能性",
  "Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.": "频率惩罚. 正值根据新token在至今的文本中出现的频率/次数, 来对其进行惩罚, 从而减少模型原封不动地重复相同句子的可能性",
  "int8 uses less VRAM, but has slightly lower quality. fp16 has higher quality, and fp32 has the best quality.": "int8占用显存更低, 但质量略微下降. fp16质量更好, fp32质量最好",
  "Number of the neural network layers loaded into VRAM, the more you load, the faster the speed, but it consumes more VRAM. (If your VRAM is not enough, it will fail to load)": "载入显存的神经网络层数, 载入越多, 速度越快, 但显存消耗越大 (如果你的显存不够, 会载入失败)",
  "Whether to use CPU to calculate the last output layer of the neural network with FP32 precision to obtain better quality.": "是否使用cpu以fp32精度计算神经网络的最后一层输出层, 以获得更好的质量",
  "Downloads": "下载",
  "Pause": "暂停",
  "Continue": "继续",
  "Resume": "继续",
  "Check": "查看",
  "Model file not found": "模型文件不存在",
  "Can not find download url": "找不到下载地址",
  "Python target not found, would you like to download it?": "没有找到目标Python, 是否下载?",
  "Python dependencies are incomplete, would you like to install them?": "Python依赖缺失, 是否安装?",
  "Install": "安装",
  "This is the latest version": "已是最新版",
  "Use Tsinghua Pip Mirrors": "使用清华大学Pip镜像源",
  "Model Config Exception": "模型配置异常",
  "Use Gitee Updates Source": "使用Gitee更新源",
  "Use Custom CUDA kernel to Accelerate": "使用自定义CUDA算子加速",
  "Enabling this option can greatly improve inference speed and save some VRAM, but there may be compatibility issues (output garbled). If it fails to start, please turn off this option, or try to upgrade your gpu driver.": "开启这个选项能大大提升推理速度并节省显存，但可能存在兼容性(回复乱码)问题，如果发生相关问题，请关闭此选项。或更新你的显卡驱动",
  "Supported custom cuda file not found": "没有找到支持的自定义cuda文件",
  "Failed to copy custom cuda file": "自定义cuda文件复制失败",
  "Downloading update, please wait. If it is not completed, please manually download the program from GitHub and replace the original program.": "正在下载更新，请等待。如果一直未完成，请从Github手动下载并覆盖原程序",
  "Completion": "续写",
  "Parameters": "参数",
  "Stop Sequences": "停止词",
  "When this content appears in the response result, the generation will end.": "响应结果出现该内容时就结束生成",
  "Reset": "重置",
  "Generate": "生成",
  "Writer": "写作",
  "Translator": "翻译",
  "Catgirl": "猫娘",
  "Code Generation": "代码生成",
  "Werewolf": "狼人杀",
  "Instruction": "指令",
  "Blank": "空白",
  "The following is an epic science fiction masterpiece that is immortalized, with delicate descriptions and grand depictions of interstellar civilization wars.\nChapter 1.\n": "《背影》\n我与父亲不相见已二年余了，我最不能忘记的是他的背影。\n那年冬天，祖母死了，父亲的差使也交卸了，正是祸不单行的日子。我从北京到徐州，打算",
  "The following is a conversation between a cat girl and her owner. The cat girl is a humanized creature that behaves like a cat but is humanoid. At the end of each sentence in the dialogue, she will add \"Meow~\". In the following content, User represents the owner and Assistant represents the cat girl.\n\nUser: Hello.\n\nAssistant: I'm here, meow~.\n\nUser: Can you tell jokes?": "以下是一位猫娘的主人和猫娘的对话内容，猫娘是一种拟人化的生物，其行为似猫但类人，在每一句对话末尾都会加上\"喵~\"。以下内容中，User代表主人，Assistant代表猫娘。\n\nUser: 你好\n\nAssistant: 主人我在哦，喵~\n\nUser: 你会讲笑话吗?",
  "When response finished, inject this content.": "响应结束时，插入此内容到末尾",
  "Inject start text": "起始注入文本",
  "Inject end text": "结尾注入文本",
  "Before the response starts, inject this content.": "响应开始前，在开头插入此内容",
  "There is currently a game of Werewolf with six players, including a Seer (who can check identities at night), two Werewolves (who can choose someone to kill at night), a Bodyguard (who can choose someone to protect at night), two Villagers (with no special abilities), and a game host. User will play as Player 1, Assistant will play as Players 2-6 and the game host, and they will begin playing together. Every night, the host will ask User for his action and simulate the actions of the other players. During the day, the host will oversee the voting process and ask User for his vote. \n\nAssistant: Next, I will act as the game host and assign everyone their roles, including randomly assigning yours. Then, I will simulate the actions of Players 2-6 and let you know what happens each day. Based on your assigned role, you can tell me your actions and I will let you know the corresponding results each day.\n\nUser: Okay, I understand. Let's begin. Please assign me a role. Am I the Seer, Werewolf, Villager, or Bodyguard?\n\nAssistant: You are the Seer. Now that night has fallen, please choose a player to check his identity.\n\nUser: Tonight, I want to check Player 2 and find out his role.": "现在有一场六人狼人杀游戏，包括一名预言家(可以在夜晚查验身份)，两名狼人(可以在夜晚选择杀人)，一名守卫(可以在夜晚选择要守护的人)，两名平民（无技能)，一名主持人，以下内容中User将扮演其中的1号玩家，Assistant来扮演2-6号玩家，以及主持人，并开始与User进行游戏，主持人每晚都会询问User的行动，并模拟其他人的行动，在白天则要主持投票，并同样询问User投票对象，公布投票结果。\n\nAssistant: 接下来，我将首先作为主持人进行角色分配，并给你赋予随机的角色，之后我将模拟2-6号玩家进行行动，告知你每天的动态，根据你被分配的角色，你可以回复我你做的行动，我会告诉你每天对应的结果\n\nUser: 好的，我明白了，那么开始吧。请先给我一个角色身份。我是预言家，狼人，平民，守卫中的哪一个呢？\n\nAssistant: 你的身份是预言家。现在夜晚降临，请选择你要查验的玩家。\n\nUser: 今晚我要验2号玩家，他是什么身份？",
  "Writer, Translator, Role-playing": "写作，翻译，角色扮演",
  "Chinese Kongfu": "情境冒险",
  "Allow external access to the API (service must be restarted)": "允许外部访问API (必须重启服务)",
  "Custom": "自定义",
  "CUDA (Beta, Faster)": "CUDA (Beta, 更快)",
  "Reset All Configs": "重置所有配置",
  "Cancel": "取消",
  "Confirm": "确认",
  "Are you sure you want to reset all configs? This will obtain the latest preset configs, but will override your custom configs and cannot be undone.": "你确定要重置所有配置吗？这会获取最新的预设配置，但会覆盖你的自定义配置，并且无法撤销",
  "Advanced": "高级",
  "Custom Python Path": "自定义Python路径",
  "Custom Models Path": "自定义模型路径",
  "Microsoft Visual C++ Redistributable is not installed, would you like to download it?": "微软VC++组件未安装, 是否下载?",
  "File Path Cannot Contain Space": "文件路径不能包含空格",
  "Current Strategy": "当前Strategy",
  "MacOS is not yet supported for performing this operation, please do it manually.": "MacOS尚未支持此操作, 请手动执行",
  "Linux is not yet supported for performing this operation, please do it manually.": "Linux尚未支持此操作, 请手动执行",
  "On Linux system, you must manually install python dependencies.": "在Linux系统下, 你必须手动安装python依赖",
  "Update completed, please restart the program.": "更新完成, 请重启程序",
  "Are you sure you want to reset this page? It cannot be undone.": "你确定要重置本页吗？这无法撤销",
  "Model file download is not complete": "模型文件下载未完成",
  "Error": "错误",
  "Are you sure you want to clear the conversation? It cannot be undone.": "你确定要清空对话吗？这无法撤销",
  "Save": "保存",
  "Conversation Saved": "对话已保存",
  "Open": "打开",
  "DPI Scaling": "显示缩放",
  "Restart the app to apply DPI Scaling.": "重启应用以使显示缩放生效",
  "Restart": "重启",
  "API Chat Model Name": "API聊天模型名",
  "API Completion Model Name": "API续写模型名",
  "Localhost": "本地",
  "Retry": "重试",
  "Delete": "删除",
  "Edit": "编辑",
  "Memory is not enough, try to increase the virtual memory or use a smaller model.": "内存不足，尝试增加虚拟内存，或使用一个更小规模的模型",
  "Bad PyTorch version, please reinstall PyTorch with cuda.": "错误的PyTorch版本，请重新安装CUDA版本的PyTorch",
  "The model file is corrupted, please download again.": "模型文件损坏，请重新下载",
  "Found no NVIDIA driver, please install the latest driver.": "没有找到NVIDIA驱动，请安装最新驱动",
  "VRAM is not enough, please reduce stored layers or use a lower precision in Configs page.": "显存不足，请在配置页面减少载入显存层数，或使用更低的精度",
  "Failed to enable custom CUDA kernel, ninja is required to load C++ extensions. You may be using the CPU version of PyTorch, please reinstall PyTorch with CUDA. Or if you are using a custom Python interpreter, you must compile the CUDA kernel by yourself or disable Custom CUDA kernel acceleration.": "自定义CUDA算子开启失败，需要安装Ninja来读取C++扩展。你可能正在使用CPU版本的PyTorch，请重新安装CUDA版本的PyTorch。如果你正在使用自定义Python解释器，你必须自己编译CUDA算子或禁用自定义CUDA算子加速",
  "Presets": "预设",
  "Online": "在线",
  "english": "英文",
  "chinese": "中文",
  "default": "默认",
  "japanese": "日文",
  "New Preset": "新建预设",
  "Import": "导入",
  "Name": "名称",
  "Imported successfully": "导入成功",
  "Failed to import. Please copy a preset to the clipboard.": "导入失败。请复制一个预设到剪贴板",
  "Clipboard is empty.": "剪贴板没有内容",
  "Successfully copied to clipboard.": "成功复制到剪贴板",
  "Edit Character Settings": "编辑人设",
  "Go Back": "返回",
  "Description": "描述",
  "Avatar Url": "头像图片地址",
  "Welcome Message": "欢迎语",
  "Display Preset Messages": "显示预设中的对话",
  "Tag": "标签",
  "Activate": "激活",
  "New": "新建",
  "user": "用户",
  "assistant": "AI",
  "system": "系统",
  "Regenerate": "重新生成",
  "LoRA Finetune": "LoRA微调",
  "Command Stopped": "命令已终止",
  "Please convert data first.": "请先转换数据",
  "Ubuntu is not installed, do you want to install it?": "Ubuntu未安装，是否安装？",
  "Install Ubuntu": "安装Ubuntu",
  "Please install Ubuntu using Microsoft Store, after installation click the Open button in Microsoft Store and then click the Train button": "请用Microsoft Store安装Ubuntu，安装完成后，点击Microsoft Store界面的“打开”按钮，然后点击“训练”按钮",
  "WSL is not enabled, do you want to enable it?": "WSL未启用，是否启用？",
  "Enable WSL": "启用WSL",
  "After installation, please restart your computer to enable WSL": "安装完成后，请重启电脑以启用WSL",
  "Data Process": "数据处理",
  "Data Path": "数据路径",
  "Vocab Path": "词表路径",
  "Train Parameters": "训练参数",
  "Base Model": "基底模型",
  "LoRA Model": "LoRA模型",
  "Merge Model": "合并模型",
  "Devices": "显卡数量",
  "Gradient Checkpoint": "梯度检查点标志",
  "Context Length": "上下文长度",
  "Epoch Steps": "每轮训练步数",
  "Epoch Count": "训练轮次",
  "Epoch Begin": "起始轮次",
  "Epoch Save": "保存间隔轮次",
  "Learning Rate Init": "初始学习率",
  "Learning Rate Final": "最终学习率",
  "Micro Batch Size": "微批次大小",
  "Accumulate Gradient Batches": "梯度累积批次",
  "Warmup Steps": "学习率预热步数",
  "Pre-FFN": "前馈网络预处理",
  "None": "空",
  "Merge model successfully": "合并模型成功",
  "Convert Data successfully": "数据转换成功",
  "Please select a LoRA model": "请选择一个LoRA模型",
  "You are using sample data for training. For formal training, please make sure to create your own jsonl file.": "你正在使用示例数据训练，对于正式训练场合，请务必创建你自己的jsonl训练数据",
  "WSL is not running, please retry. If it keeps happening, it means you may be using an outdated version of WSL, run \"wsl --update\" to update.": "WSL没有运行，请重试。如果一直出现此错误，意味着你可能正在使用旧版本的WSL，请在cmd执行\"wsl --update\"以更新",
  "Memory is not enough, try to increase the virtual memory (Swap of WSL) or use a smaller base model.": "内存不足，尝试增加虚拟内存(WSL Swap)，或使用一个更小规模的基底模型",
  "VRAM is not enough": "显存不足",
  "Training data is not enough, reduce context length or add more data for training": "训练数据不足，请减小上下文长度或增加训练数据",
  "You are using WSL 1 for training, please upgrade to WSL 2. e.g. Run \"wsl --set-version Ubuntu-22.04 2\"": "你正在使用WSL 1进行训练，请升级到WSL 2。例如，运行\"wsl --set-version Ubuntu-22.04 2\"",
  "Matched CUDA is not installed": "未安装匹配的CUDA",
  "Failed to convert data": "数据转换失败",
  "Failed to merge model": "合并模型失败",
  "The data path should be a directory or a file in jsonl format (more formats will be supported in the future).\n\nWhen you provide a directory path, all the txt files within that directory will be automatically converted into training data. This is commonly used for large-scale training in writing, code generation, or knowledge bases.\n\nThe jsonl format file can be referenced at https://github.com/Abel2076/json2binidx_tool/blob/main/sample.jsonl.\nYou can also write it similar to OpenAI's playground format, as shown in https://platform.openai.com/playground/p/default-chat.\nEven for multi-turn conversations, they must be written in a single line using `\\n` to indicate line breaks. If they are different dialogues or topics, they should be written in separate lines.": "数据路径必须是一个文件夹，或者jsonl格式文件 (未来会支持更多格式)\n\n当你填写的路径是一个文件夹时，该文件夹内的所有txt文件会被自动转换为训练数据，通常这用于大批量训练写作，代码生成或知识库\n\njsonl文件的格式参考 https://github.com/Abel2076/json2binidx_tool/blob/main/sample.jsonl\n你也可以仿照openai的playground编写，参考 https://platform.openai.com/playground/p/default-chat\n即使是多轮对话也必须写在一行，用`\\n`表示换行，如果是不同对话或主题，则另起一行",
  "Size mismatch for blocks. You are attempting to continue training from the LoRA model, but it does not match the base model. Please set LoRA model to None.": "尺寸不匹配块。你正在尝试从LoRA模型继续训练，但该LoRA模型与基底模型不匹配，请将LoRA模型设为空",
  "Instruction: Write a story using the following information\n\nInput: A man named Alex chops a tree down\n\nResponse:": "Instruction: Write a story using the following information\n\nInput: 艾利克斯砍倒了一棵树\n\nResponse:",
  "Composition": "作曲",
  "Use Local Sound Font": "使用本地音色资源",
  "Auto Play At The End": "结束时自动播放",
  "No File to save": "无文件可保存",
  "File Saved": "文件已保存",
  "Failed to load local sound font, please check if the files exist - assets/sound-font": "加载本地音色资源失败，请检查文件是否存在 - assets/sound-font",
  "Please convert model to safe tensors format first": "请先将模型转换为Safetensors格式",
  "Convert To Safe Tensors Format": "转换为Safetensors格式",
  "Please change Strategy to WebGPU to use safetensors format": "请将Strategy改为WebGPU以使用safetensors格式",
  "Preview Only": "仅预览",
  "RAM": "内存",
  "VRAM": "显存",
  "GPU Usage": "GPU占用",
  "Use Custom Tokenizer": "使用自定义Tokenizer",
  "Tokenizer Path (e.g. backend-python/rwkv_pip/20B_tokenizer.json)": "Tokenizer路径 (例如: backend-python/rwkv_pip/20B_tokenizer.json)",
  "User Name": "用户名称",
  "Assistant Name": "AI名称",
  "Insert default system prompt at the beginning": "在开头自动插入默认系统提示",
  "Format Content": "规范格式"
}